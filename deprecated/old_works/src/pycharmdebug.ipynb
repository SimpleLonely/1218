{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, log_loss, confusion_matrix, f1_score\n",
    "from bt_classes import my_backtest, test_indicator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "#importing required libraries\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, CuDNNLSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "from sa import *\n",
    "from utils import *\n",
    "# follow the literature\n",
    "# we don't use min-max scaling here, use partial mean-std scaling instead\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import chain\n",
    "rcParams['figure.figsize'] = 20,10\n",
    "# df = pd.read_csv('../res/input0130.csv')\n",
    "\n",
    "orig_df = pd.read_csv('../xau_1d_20y.csv')\n",
    "orig_df['datetime'] = pd.to_datetime(orig_df['date'])\n",
    "orig_df = orig_df.set_index('datetime')\n",
    "\n",
    "df = orig_df.copy()\n",
    "df['log_r'] = np.log(df['close']) - np.log(df['open'])\n",
    "df['label'] = np.sign(df['log_r'].shift(-1))\n",
    "df['label'][df['label']==-1] = 0\n",
    "df['label'] = df['label'].fillna(0)\n",
    "\n",
    "\n",
    "# Please select the last activation layer.\n",
    "layer_names = ['lstm_2']\n",
    "\n",
    "default_upper_bound = 2000\n",
    "default_n_bucket = 1000\n",
    "default_n_classes = 2\n",
    "class Args(): #创建一个类\n",
    "    def __init__(self): #定义初始化信息。\n",
    "        self.is_classification = True\n",
    "        self.save_path = ''\n",
    "        self.d = 'lstm_r'\n",
    "        self.num_classes = 2\n",
    "        self.lsa = True\n",
    "        self.dsa = True\n",
    "        self.target = 'none'\n",
    "        self.batch_size = 128\n",
    "        self.var_threshold = 1e-5\n",
    "        self.upper_bound = 2000\n",
    "        self.n_bucket = 1000\n",
    "        self.is_classification = True\n",
    "args = Args()\n",
    "\n",
    "def lstm_model(sample_len=240,para_a=42, para_b=17,drop1=0.05,drop2=0.02):\n",
    "    model = Sequential()\n",
    "    # model.add(LSTM(units=para_a, dropout=0.1, return_sequences=True, input_shape=(sample_len,1),activation='tanh'))# (25,15)-57, (42,17)-58\n",
    "    # model.add(LSTM(units=para_b, dropout=0.08, activation='tanh'))\n",
    "    model.add(CuDNNLSTM(units=para_a, return_sequences=True, input_shape=(sample_len,1)))# (25,15)-57, (42,17)-58\n",
    "    model.add(Dropout(drop1))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(CuDNNLSTM(units=para_b))\n",
    "    model.add(Dropout(drop2))\n",
    "    model.add(Activation('tanh'))\n",
    "    # model.add(Dropout(0.08))# 加了之后同原先效果差不多，（应该一定程度上）可以防止过拟合\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# this experiment is intended for trying to calculate the transition probability matrix rollingly.\n",
    "# firstly let's define some useful functions\n",
    "def get_transtitions(y_true, y_pred):\n",
    "    '''\n",
    "    To generate transition probability matrix with y_true, y_pred of an any period.\n",
    "    '''\n",
    "    y_output = y_pred\n",
    "    y = y_true\n",
    "    continues_suc = 0\n",
    "    continues_fail = 0\n",
    "    result = []\n",
    "    maxx = 0\n",
    "    for i in range(0,len(y_output)):\n",
    "        if y_output[i] == y[i]:\n",
    "            continues_suc+=1\n",
    "            if continues_fail!=0:\n",
    "                result.append(-continues_fail)\n",
    "                if continues_fail > maxx:\n",
    "                    maxx = continues_fail\n",
    "                continues_fail = 0\n",
    "        else:\n",
    "            continues_fail+=1\n",
    "            if continues_suc != 0:\n",
    "                result.append(continues_suc)\n",
    "                if continues_suc > maxx:\n",
    "                    maxx = continues_suc\n",
    "                continues_suc = 0\n",
    "\n",
    "    length = maxx+1\n",
    "    suc_result = [[0] * length for i in range(length)]\n",
    "    fail_result = [[0]*length for i in range(length)]\n",
    "\n",
    "    for i in range(len(result)-1):\n",
    "        if result[i]>0:\n",
    "            suc_result[result[i]][-result[i+1]]+=1\n",
    "        else:\n",
    "            fail_result[-result[i]][result[i+1]]+=1\n",
    "    return suc_result, fail_result\n",
    "\n",
    "def get_trans_prob(suc_result, fail_result, weighted=False):\n",
    "    status_porb = {}\n",
    "    if weighted:\n",
    "        for i in range(len(suc_result)):\n",
    "            fail = np.sum([j*suc_result[i][j] for j in range(len(suc_result[i]))])\n",
    "            if i+1 < len(suc_result):\n",
    "                success = np.sum([(j-i)*np.sum(suc_result[j]) for j in range(i+1,len(suc_result))])\n",
    "                # success = np.sum(suc_result[i+1:])\n",
    "            else: \n",
    "                success = 0\n",
    "            status_porb[i] = success / (success + fail)\n",
    "\n",
    "        for i in range(len(fail_result)):\n",
    "            success = np.sum([j*fail_result[i][j] for j in range(len(fail_result[i]))])\n",
    "            if i+1 < len(fail_result):\n",
    "                fail = np.sum([(j-i)*np.sum(fail_result[j]) for j in range(i+1,len(fail_result))])\n",
    "                # fail = np.sum(fail_result[i+1:])\n",
    "            else: \n",
    "                fail = 0\n",
    "            status_porb[-i] = success / (success + fail)\n",
    "    else:\n",
    "        for i in range(len(suc_result)):\n",
    "            fail = np.sum(suc_result[i])\n",
    "            if i+1 < len(suc_result):\n",
    "                success = np.sum(suc_result[i+1:])\n",
    "            else: \n",
    "                success = 0\n",
    "            status_porb[i] = success / (success + fail)\n",
    "\n",
    "        for i in range(len(fail_result)):\n",
    "            success = np.sum(fail_result[i])\n",
    "            if i+1 < len(fail_result):\n",
    "                fail = np.sum(fail_result[i+1:])\n",
    "            else: \n",
    "                fail = 0\n",
    "            status_porb[-i] = success / (success + fail)\n",
    "    return status_porb\n",
    "\n",
    "def trans_prob(y_true, y_pred, weighted=False):\n",
    "    suc_result, fail_result = get_transtitions(y_true, y_pred)\n",
    "    return get_trans_prob(suc_result, fail_result, weighted)\n",
    "\n",
    "def get_suc_num(test_df):\n",
    "    test_df['win'] = -1\n",
    "    test_df['win'].loc[test_df['y_true']==test_df['y_pred']] = 1\n",
    "    test_df['suc_num'] = np.nan\n",
    "    test_df['suc_num'].loc[test_df['win']!=test_df['win'].shift(1)] = 1\n",
    "    test_df['suc_num'] = test_df['suc_num'].cumsum().fillna(method='ffill')\n",
    "    test_df['suc_num'] = test_df.groupby('suc_num')['suc_num'].cumsum() / test_df['suc_num'] * test_df['win']\n",
    "    return test_df['suc_num']\n",
    "\n",
    "def get_adj_metrics(test_df):\n",
    "    pre_acc = accuracy_score(test_df['y_true'],test_df['y_pred'])\n",
    "    pre_pre = precision_score(test_df['y_true'],test_df['y_pred'],labels=[0,1])\n",
    "    pre_rec = recall_score(test_df['y_true'],test_df['y_pred'],labels=[0,1])\n",
    "    pre_f1 = f1_score(test_df['y_true'],test_df['y_pred'],labels=[0,1])\n",
    "    pre_cm = confusion_matrix(test_df['y_true'],test_df['y_pred'],labels=[0,1])\n",
    "    pre_cm00,pre_cm01,pre_cm10,pre_cm11 = pre_cm[0][0],pre_cm[0][1],pre_cm[1][0],pre_cm[1][1]\n",
    "    after_acc = accuracy_score(test_df['y_true'],test_df['adjusted_pred'])\n",
    "    after_pre = precision_score(test_df['y_true'],test_df['adjusted_pred'],labels=[0,1])\n",
    "    after_rec = recall_score(test_df['y_true'],test_df['adjusted_pred'],labels=[0,1])\n",
    "    after_f1 = f1_score(test_df['y_true'],test_df['adjusted_pred'],labels=[0,1])\n",
    "    after_cm = confusion_matrix(test_df['y_true'],test_df['adjusted_pred'],labels=[0,1])\n",
    "    after_cm00,after_cm01,after_cm10,after_cm11 = after_cm[0][0],after_cm[0][1],after_cm[1][0],after_cm[1][1]\n",
    "    \n",
    "    test_df['label'] = test_df['y_pred'].shift(-1).fillna(0)\n",
    "    pre_adj,pre_dd,pre_ar = my_backtest(test_df.iloc[fit_window:])\n",
    "    test_df['label'] = test_df['adjusted_pred'].shift(-1).fillna(0)\n",
    "    after_adj,after_dd,after_ar = my_backtest(test_df.iloc[fit_window:])\n",
    "\n",
    "    test_df['adj_true'] = 1\n",
    "    test_df['adj_true'].loc[test_df['y_true']==test_df['y_pred']] = 0\n",
    "    test_df['adj_pred'] = 1\n",
    "    test_df['adj_pred'].loc[test_df['adjusted_pred']==test_df['y_pred']] = 0\n",
    "    adj_acc = accuracy_score(test_df['adj_true'],test_df['adj_pred'])\n",
    "    adj_pre = precision_score(test_df['adj_true'],test_df['adj_pred'],labels=[0,1])\n",
    "    adj_rec = recall_score(test_df['adj_true'],test_df['adj_pred'],labels=[0,1])\n",
    "    adj_f1 = f1_score(test_df['adj_true'],test_df['adj_pred'],labels=[0,1])\n",
    "    adj_cm = confusion_matrix(test_df['adj_true'],test_df['adj_pred'],labels=[0,1])\n",
    "    adj_cm00,adj_cm01,adj_cm10,adj_cm11 = adj_cm[0][0],adj_cm[0][1],adj_cm[1][0],adj_cm[1][1]\n",
    "\n",
    "    test_df['log_profit'] = 2*(test_df['y_pred']-0.5)*test_df['log_r']\n",
    "    win_profit = test_df['log_profit'].loc[test_df['y_true']==test_df['y_pred']].mean()\n",
    "    lose_profit = test_df['log_profit'].loc[test_df['y_true']!=test_df['y_pred']].mean()\n",
    "    pre_wtl = abs(win_profit / lose_profit)\n",
    "    adj_win_profit = test_df['log_profit'].loc[test_df['y_true']==test_df['adjusted_pred']].mean()\n",
    "    adj_lose_profit = test_df['log_profit'].loc[test_df['y_true']!=test_df['adjusted_pred']].mean()\n",
    "    adj_wtl = abs(adj_win_profit / adj_lose_profit)\n",
    "\n",
    "    return [pre_acc,pre_pre,pre_rec,pre_f1,pre_cm00,pre_cm01,pre_cm10,pre_cm11,after_acc,after_pre,after_rec,after_f1,after_cm00,after_cm01,after_cm10,after_cm11,pre_adj,pre_dd,pre_ar,after_adj,after_dd,after_ar,adj_acc,adj_pre,adj_rec,adj_f1,adj_cm00,adj_cm01,adj_cm10,adj_cm11,win_profit,lose_profit,pre_wtl,adj_win_profit,adj_lose_profit,adj_wtl]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Starting Portfolio Value: 100000.00\nFinal Portfolio Value: 99861.00\nSharpe: -0.02\nMax drawdown: 20.44%\nAnnual rate: -0.07%\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# reproduce training set\n",
    "sample_len = 9\n",
    "p1 = 192\n",
    "p2 = 192\n",
    "epochs = 30\n",
    "batch_size = 200\n",
    "train_len = 1500\n",
    "test_len = 500\n",
    "weighted = False\n",
    "fit_window = 100\n",
    "\n",
    "train_begin = sample_len\n",
    "train_end = train_begin + train_len\n",
    "test_begin = train_end + sample_len\n",
    "test_end = test_begin + test_len\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_set = df[['log_r','label']][train_begin-sample_len:train_end].reset_index()\n",
    "x_train, y_train = [], []\n",
    "x_train_set = list(chain.from_iterable(scaler.fit_transform(train_set['log_r'].values.reshape(-1,1))))\n",
    "for i in range(sample_len,len(x_train_set)):\n",
    "    x_train.append(x_train_set[i-sample_len:i])\n",
    "    y_train.append(train_set['label'][i])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "y_train = to_categorical(y_train,2)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1)) \n",
    "\n",
    "model_name = f'd{sample_len}-{p1}_{p2}_{epochs}_{batch_size}.h5'\n",
    "if os.path.exists(model_name):\n",
    "    model = load_model(model_name)\n",
    "else:\n",
    "    model = lstm_model(sample_len=sample_len,para_a=p1,para_b=p2)\n",
    "    model.fit(x_train,y_train,epochs=epochs, batch_size=batch_size, callbacks=[EarlyStopping(monitor='loss',patience=10)])\n",
    "    model.save(model_name)\n",
    "\n",
    "\n",
    "x_test, y_test = [], []\n",
    "test_set = df[['log_r','label']][test_begin-sample_len:test_end].reset_index()\n",
    "test_df = df[test_begin:test_end].copy()\n",
    "x_test_set = list(chain.from_iterable(scaler.transform(test_set['log_r'].values.reshape(-1,1))))\n",
    "for i in range(sample_len,len(x_test_set)):\n",
    "    x_test.append(x_test_set[i-sample_len:i])\n",
    "    y_test.append(test_set['label'][i-1])\n",
    "test_df['y_true'] = y_test\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1)) \n",
    "y_test = to_categorical(y_test,2)\n",
    "y_pred = model.predict_classes(x_test)\n",
    "test_df['y_pred'] = y_pred\n",
    "test_loss,test_acc = model.evaluate(x_test, y_test,verbose=0)\n",
    "precision = precision_score(test_df['y_true'],test_df['y_pred'],labels=[0,1])\n",
    "recall = recall_score(test_df['y_true'],test_df['y_pred'],labels=[0,1])\n",
    "f1 = f1_score(test_df['y_true'],test_df['y_pred'],labels=[0,1])\n",
    "cm = confusion_matrix(test_df['y_true'],test_df['y_pred'],labels=[0,1])\n",
    "cm00,cm01,cm10,cm11 = cm[0][0],cm[0][1],cm[1][0],cm[1][1]\n",
    "test_df['log_profit'] = 2*(test_df['y_pred']-0.5)*test_df['log_r']\n",
    "win_profit = test_df['log_profit'].loc[test_df['y_true']==test_df['y_pred']].sum()\n",
    "lose_profit = test_df['log_profit'].loc[test_df['y_true']!=test_df['y_pred']].sum()\n",
    "wtl = abs(win_profit / lose_profit)\n",
    "test_df['label'] = test_df['y_pred'].shift(-1)\n",
    "sharpe, dd, ar = my_backtest(test_df)\n",
    "result1 = [test_loss,test_acc,precision,recall,f1,cm00,cm01,cm10,cm11,win_profit,lose_profit,wtl,sharpe,dd,ar]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Starting Portfolio Value: 100000.00\nFinal Portfolio Value: 112486.00\nSharpe: 1.06\nMax drawdown: 5.32%\nAnnual rate: 10.39%\nStarting Portfolio Value: 100000.00\n",
      "Final Portfolio Value: 97947.00\nSharpe: -0.24\nMax drawdown: 10.12%\nAnnual rate: -1.73%\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "## 滚动的测试：先把全部预测、连续对错状态都算出来，再遍历判断修改,使用短期历史对错法则\n",
    "# test_len = 500\n",
    "# test_begin = train_end\n",
    "# test_end = test_begin + test_len\n",
    "\n",
    "\n",
    "x_test, y_test = [], []\n",
    "test_set = df[['log_r','label']][test_begin-sample_len:test_end].reset_index()\n",
    "test_df = df[test_begin:test_end]\n",
    "x_test_set = list(chain.from_iterable(scaler.transform(test_set['log_r'].values.reshape(-1,1))))\n",
    "for i in range(sample_len,len(x_test_set)):\n",
    "    x_test.append(x_test_set[i-sample_len:i])\n",
    "    y_test.append(test_set['label'][i-1])\n",
    "test_df['y_true'] = y_test\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1)) \n",
    "y_test = to_categorical(y_test,2)\n",
    "\n",
    "y_pred = model.predict_classes(x_test)\n",
    "test_df['y_pred'] = y_pred\n",
    "\n",
    "# prob_save = []\n",
    "# test_df['suc_num'] = get_suc_num(test_df)\n",
    "test_df['win'] = 0\n",
    "test_df['win'].loc[test_df['y_true']==test_df['y_pred']] = 1\n",
    "\n",
    "win_rate = [1] * fit_window\n",
    "for i in range(fit_window, len(test_df)):\n",
    "    true_prob = test_df['win'].iloc[i-fit_window:i].sum() / fit_window\n",
    "    # this_true = test_df['y_true'].iloc[i-fit_window:i]\n",
    "    # this_pred = test_df['y_pred'].iloc[i-fit_window:i]\n",
    "    # this_prob = trans_prob(this_true,this_pred,weighted)\n",
    "    # last_suc = test_df['suc_num'].iloc[i-1]\n",
    "    # if last_suc not in this_prob.keys():\n",
    "    #     if last_suc > 0:\n",
    "    #         this_win = 0\n",
    "    #     else:\n",
    "    #         this_win = 1\n",
    "    # else:\n",
    "    #     this_win = this_prob[last_suc] \n",
    "    # prob_save.append(this_prob)\n",
    "    win_rate.append(true_prob)\n",
    "test_df['win_rate'] = win_rate\n",
    "test_df['adjusted_pred'] = test_df['y_pred']\n",
    "test_df['adjusted_pred'].loc[test_df['win_rate']<0.5] = 1 - test_df['adjusted_pred'].loc[test_df['win_rate']<0.5]\n",
    "result2 = get_adj_metrics(test_df.iloc[fit_window:])\n",
    "# pre_acc = accuracy_score(test_df['y_true'].iloc[fit_window:],test_df['y_pred'].iloc[fit_window:])\n",
    "# after_acc = accuracy_score(test_df['y_true'].iloc[fit_window:],test_df['adjusted_pred'].iloc[fit_window:])\n",
    "# # test_df = orig_df[test_begin+fit_window:test_end]\n",
    "# # test_df['label'] = y_pred\n",
    "# # print(accuracy_score(y_true,y_pred))\n",
    "\n",
    "# # adjusted_df = orig_df[test_begin+fit_window:test_end]\n",
    "# # adjusted_df['label'] = test_df['adjusted_pred']\n",
    "# # print(accuracy_score(y_true,adjusted_df['label']))\n",
    "# print(f'Pre-adjustment accuracy: {pre_acc:.4f}')\n",
    "# test_df['label'] = test_df['y_pred'].shift(-1).fillna(0)\n",
    "# my_backtest(test_df.iloc[fit_window:])\n",
    "# print(f'Adjusted accuracy: {after_acc:.4f}')\n",
    "# test_df['label'] = test_df['adjusted_pred'].shift(-1).fillna(0)\n",
    "# my_backtest(test_df.iloc[fit_window:])\n",
    "\n",
    "# test_df['log_profit'] = 2*(test_df['y_pred']-0.5)*test_df['log_r']\n",
    "# win_profit = test_df['log_profit'].loc[test_df['y_true']==test_df['y_pred']].mean()\n",
    "# lose_profit = test_df['log_profit'].loc[test_df['y_true']!=test_df['y_pred']].mean()\n",
    "# pre_wtl = abs(win_profit / lose_profit)\n",
    "# adj_win_profit = test_df['log_profit'].loc[test_df['y_true']==test_df['adjusted_pred']].mean()\n",
    "# adj_lose_profit = test_df['log_profit'].loc[test_df['y_true']!=test_df['adjusted_pred']].mean()\n",
    "# adj_wtl = abs(adj_win_profit / adj_lose_profit)\n",
    "# win_profit,lose_profit,pre_wtl,adj_win_profit,adj_lose_profit,adj_wtl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df['label'].iloc[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Starting Portfolio Value: 100000.00\nFinal Portfolio Value: 112486.00\nSharpe: 1.06\nMax drawdown: 5.32%\nAnnual rate: 10.39%\nStarting Portfolio Value: 100000.00\n",
      "Final Portfolio Value: 99534.00\nSharpe: -0.12\nMax drawdown: 6.92%\nAnnual rate: -0.39%\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "## 滚动的测试：先把全部预测、连续对错状态都算出来，再遍历判断修改\n",
    "# test_len = 500\n",
    "# weighted = False\n",
    "# test_begin = train_end\n",
    "# test_end = test_begin + test_len\n",
    "\n",
    "x_test, y_test = [], []\n",
    "test_set = df[['log_r','label']][test_begin-sample_len:test_end].reset_index()\n",
    "test_df = df[test_begin:test_end].copy()\n",
    "x_test_set = list(chain.from_iterable(scaler.transform(test_set['log_r'].values.reshape(-1,1))))\n",
    "for i in range(sample_len,len(x_test_set)):\n",
    "    x_test.append(x_test_set[i-sample_len:i])\n",
    "    y_test.append(test_set['label'][i-1])\n",
    "test_df['y_true'] = y_test\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1)) \n",
    "y_test = to_categorical(y_test,2)\n",
    "\n",
    "y_pred = model.predict_classes(x_test)\n",
    "test_df['y_pred'] = y_pred\n",
    "\n",
    "# fit_window = 100\n",
    "# weighted = False\n",
    "\n",
    "# prob_save = []\n",
    "# test_df = df[test_begin:test_end]\n",
    "# test_df['y_true'] = y_true\n",
    "# test_df['y_pred'] = y_pred\n",
    "test_df['suc_num'] = get_suc_num(test_df)\n",
    "\n",
    "win_rate = [1] * fit_window\n",
    "for i in range(fit_window, len(test_df)):\n",
    "    this_true = test_df['y_true'].iloc[i-fit_window:i]\n",
    "    this_pred = test_df['y_pred'].iloc[i-fit_window:i]\n",
    "    this_prob = trans_prob(this_true,this_pred,weighted)\n",
    "    last_suc = test_df['suc_num'].iloc[i-1]\n",
    "    if last_suc not in this_prob.keys():\n",
    "        if last_suc > 0:\n",
    "            this_win = 0\n",
    "        else:\n",
    "            this_win = 1\n",
    "    else:\n",
    "        this_win = this_prob[last_suc] \n",
    "    # prob_save.append(this_prob)\n",
    "    win_rate.append(this_win)\n",
    "test_df['win_rate'] = win_rate\n",
    "test_df['adjusted_pred'] = test_df['y_pred']\n",
    "test_df['adjusted_pred'].loc[test_df['win_rate']<0.5] = 1 - test_df['adjusted_pred'].loc[test_df['win_rate']<0.5]\n",
    "\n",
    "result3 = get_adj_metrics(test_df.iloc[fit_window:])\n",
    "\n",
    "# pre_acc = accuracy_score(test_df['y_true'].iloc[fit_window:],test_df['y_pred'].iloc[fit_window:])\n",
    "# after_acc = accuracy_score(test_df['y_true'].iloc[fit_window:],test_df['adjusted_pred'].iloc[fit_window:])\n",
    "# print(f'Pre-adjustment accuracy: {pre_acc:.4f}')\n",
    "# test_df['label'] = test_df['y_pred'].shift(-1).fillna(0)\n",
    "# my_backtest(test_df.iloc[fit_window:])\n",
    "# print(f'Adjusted accuracy: {after_acc:.4f}')\n",
    "# test_df['label'] = test_df['adjusted_pred'].shift(-1).fillna(0)\n",
    "# my_backtest(test_df.iloc[fit_window:])\n",
    "\n",
    "# test_df['log_profit'] = 2*(test_df['y_pred']-0.5)*test_df['log_r']\n",
    "# win_profit = test_df['log_profit'].loc[test_df['y_true']==test_df['y_pred']].mean()\n",
    "# lose_profit = test_df['log_profit'].loc[test_df['y_true']!=test_df['y_pred']].mean()\n",
    "# pre_wtl = abs(win_profit / lose_profit)\n",
    "# adj_win_profit = test_df['log_profit'].loc[test_df['y_true']==test_df['adjusted_pred']].mean()\n",
    "# adj_lose_profit = test_df['log_profit'].loc[test_df['y_true']!=test_df['adjusted_pred']].mean()\n",
    "# adj_wtl = abs(adj_win_profit / adj_lose_profit)\n",
    "# win_profit,lose_profit,pre_wtl,adj_win_profit,adj_lose_profit,adj_wtl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## 浮动阈值法\n",
    "## 先计算出全部输出概率值，然后挑取大者观察\n",
    "# test_len = 500\n",
    "# test_begin = train_end\n",
    "# test_end = test_begin + test_len\n",
    "\n",
    "x_test, y_test = [], []\n",
    "test_set = df[['log_r','label']][test_begin-sample_len:test_end].reset_index()\n",
    "test_set = df[['log_r','label']][test_begin-sample_len:test_end].reset_index()\n",
    "test_df = df[test_begin:test_end].copy()\n",
    "x_test_set = list(chain.from_iterable(scaler.transform(test_set['log_r'].values.reshape(-1,1))))\n",
    "for i in range(sample_len,len(x_test_set)):\n",
    "    x_test.append(x_test_set[i-sample_len:i])\n",
    "    y_test.append(test_set['label'][i-1])\n",
    "test_df['y_true'] = y_test\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1)) \n",
    "y_test = to_categorical(y_test,2)\n",
    "\n",
    "y_pred = model.predict_classes(x_test)\n",
    "test_df['y_pred'] = y_pred\n",
    "y_pred_prob = model.predict(x_test)\n",
    "\n",
    "# test_df = orig_df[test_begin:test_end]\n",
    "# test_df['y_true'] = y_true\n",
    "# test_df['y_pred'] = y_pred\n",
    "test_df['win'] = -1\n",
    "test_df['win'].loc[test_df['y_true']==test_df['y_pred']] = 1\n",
    "test_df['max_conf'] = y_pred_prob.max(axis=1)\n",
    "\n",
    "# fit_window = 100\n",
    "trust_thres = [0.5] * fit_window\n",
    "for i in range(fit_window, len(test_df)):\n",
    "    this_df = test_df.iloc[i-fit_window:i]\n",
    "    this_win = this_df['max_conf'].loc[this_df['win']==1].mean()\n",
    "    this_lose = this_df['max_conf'].loc[this_df['win']==-1].mean()\n",
    "    if this_win > this_lose:\n",
    "        threshold = (this_win + this_lose) * 0.5\n",
    "        trust_thres.append(threshold)\n",
    "    else:\n",
    "        trust_thres.append(1)\n",
    "\n",
    "test_df['trust_thres'] = threshold\n",
    "test_df['adjusted_pred'] = y_pred\n",
    "test_df['adjusted_pred'].loc[test_df['max_conf'] < test_df['trust_thres']] = 1 - test_df['adjusted_pred'].loc[test_df['max_conf'] < test_df['trust_thres']]\n",
    "\n",
    "# pre_acc = accuracy_score(test_df['y_true'].iloc[fit_window:],test_df['y_pred'].iloc[fit_window:])\n",
    "# after_acc = accuracy_score(test_df['y_true'].iloc[fit_window:],test_df['adjusted_pred'].iloc[fit_window:])\n",
    "\n",
    "# print(f'Pre-adjustment accuracy: {pre_acc:.4f}')\n",
    "# test_df['label'] = test_df['y_pred'].shift(-1).fillna(0)\n",
    "# print(my_backtest(test_df.iloc[fit_window:]))\n",
    "# print(f'Adjusted accuracy: {after_acc:.4f}')\n",
    "# test_df['label'] = test_df['adjusted_pred'].shift(-1).fillna(0)\n",
    "# print(my_backtest(test_df.iloc[fit_window:]))\n",
    "\n",
    "result4 = get_adj_metrics(test_df.iloc[fit_window:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}